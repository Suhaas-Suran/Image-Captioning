# Image Captioning with CNNs and LSTMs

This project aims to automatically generate descriptive captions for images using Convolutional Neural Networks (CNNs) for feature extraction and Long Short-Term Memory (LSTM) networks for text generation.

## Getting Started

### Installation

Clone the repository:

   ```bash
   git clone https://github.com/Suhaas-Suran/image-captioning.git
   cd image-captioning

Usage:
1. Download the dataset and pre-trained VGG16 weights (provide instructions or links if necessary).
2. Preprocess the images and captions.
3. Train the model using the preprocessed data.
4. Evaluate the model and generate captions for new images.

Model Architecture:
1. VGG16: Used for feature extraction.
2. LSTM: Used for text generation.

Results: 
BLEU-1: 0.534413
BLEU-2: 0.307770

